import streamlit as st
import pandas as pd
import re
import base64
import time  # 1. ì†ë„ ì¡°ì ˆì„ ìœ„í•´ ìƒˆë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!
from datetime import datetime
import googleapiclient.discovery
import googleapiclient.errors
import google.generativeai as genai

# --- [1. ë³´ì•ˆ ë° API ì„¤ì •] ---
try:
    YOUTUBE_KEY = st.secrets["YOUTUBE_API_KEY"]
    GEMINI_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("ğŸš¨ ë³´ì•ˆ ì„¤ì •(.streamlit/secrets.toml)ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

genai.configure(api_key=GEMINI_KEY)
model = genai.GenerativeModel('models/gemini-2.0-flash')
YOUTUBE = googleapiclient.discovery.build('youtube', 'v3', developerKey=YOUTUBE_KEY)

# --- [2. ë°ì´í„° ì„¤ì •] ---
COUNTRIES = {
    "ëŒ€í•œë¯¼êµ­": "KR", "ë¯¸êµ­": "US", "ì¼ë³¸": "JP", "ì˜êµ­": "GB", 
    "ë² íŠ¸ë‚¨": "VN", "íƒœêµ­": "TH", "ì¸ë„ë„¤ì‹œì•„": "ID", "ëŒ€ë§Œ": "TW"
}

SUB_RANGES = {
    "ì „ì²´": (0, 100000000),
    "1ë§Œ ë¯¸ë§Œ": (0, 10000),
    "1ë§Œ ~ 5ë§Œ": (10000, 50000),
    "5ë§Œ ~ 10ë§Œ": (50000, 100000),
    "10ë§Œ ~ 50ë§Œ": (100000, 500000),
    "50ë§Œ ~ 100ë§Œ": (500000, 1000000),
    "100ë§Œ ì´ìƒ": (1000000, 100000000)
}

# --- [3. UI ì„¤ì •] ---
st.set_page_config(page_title="Glowup Rizz - YOUTUBE ê²€ìƒ‰ ì—”ì§„", layout="wide")

with st.sidebar:
    try:
        st.image("logo.png", use_container_width=True)
    except:
        pass
    st.markdown("---")
    st.info("ğŸš€ **Glowup Rizz v3.9**\nAI ê³¼ë¶€í•˜ ë°©ì§€ ì‹œìŠ¤í…œ ê°€ë™ ì¤‘")

st.title("ğŸŒ YOUTUBE í¬ë¦¬ì—ì´í„° ê²€ìƒ‰ ì—”ì§„")
st.markdown("ë¬¸ì˜ 010-8900-6756")
st.markdown("---")

# --- [4. ë©”ì¸ ê²€ìƒ‰ í¼] ---
with st.form("search_form"):
    st.markdown("ğŸ“¥ **ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ ì œì™¸í•˜ê¸° (ì„ íƒ ì‚¬í•­)**")
    exclude_file = st.file_uploader("ì´ë¯¸ í™•ë³´í•œ ì±„ë„ ë¦¬ìŠ¤íŠ¸(ì—‘ì…€/CSV)ë¥¼ ì—…ë¡œë“œí•˜ë©´ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.", type=['xlsx', 'csv'])
    st.markdown("---")
    
    r1_col1, r1_col2, r1_col3 = st.columns([4, 1.2, 0.8])
    with r1_col1:
        keywords_input = st.text_input("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ì• ê²¬ ì¹´í˜, ê°•ì•„ì§€ (ì‰¼í‘œ êµ¬ë¶„)", label_visibility="collapsed")
    with r1_col2:
        selected_country = st.selectbox("ë¶„ì„ êµ­ê°€", list(COUNTRIES.keys()), label_visibility="collapsed")
    with r1_col3:
        submit_button = st.form_submit_button("ğŸš€ ê²€ìƒ‰")

    r2_col1, r2_col2, r2_col3 = st.columns(3)
    with r2_col1:
        selected_sub_range = st.selectbox("ğŸ¯ êµ¬ë…ì ë²”ìœ„ ì„ íƒ", list(SUB_RANGES.keys()))
        min_subs, max_subs = SUB_RANGES[selected_sub_range]
    with r2_col2:
        efficiency_target = st.slider("ğŸ“ˆ ìµœì†Œ ì¡°íšŒìˆ˜ íš¨ìœ¨ (%)", 0, 100, 30) / 100
    with r2_col3:
        max_res = st.number_input("ğŸ” í‚¤ì›Œë“œë‹¹ ë¶„ì„ ìˆ˜", 5, 50, 20)

st.markdown("---")

# --- [5. ë¡œì§ í•¨ìˆ˜ë“¤] ---
def extract_exclude_list(file):
    try:
        df = pd.read_csv(file) if file.name.endswith('.csv') else pd.read_excel(file)
        exclude_set = set()
        for col in df.columns:
            exclude_set.update(df[col].astype(str).str.strip().tolist())
        return exclude_set
    except: return set()

def handle_api_error(e):
    if "quotaExceeded" in str(e):
        st.error("ğŸ”´ **YouTube API í• ë‹¹ëŸ‰ì´ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.** ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        st.stop()
    else: st.error(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")

# [ìˆ˜ì •ë¨] ì´ë©”ì¼ ì¶”ì¶œ ì‹œ AI ê³¼ë¶€í•˜ ë°©ì§€ í“¨ì¦ˆ ì„¤ì¹˜
def extract_email_ai(desc):
    if not desc or len(desc.strip()) < 5: return "ì±„ë„ ì„¤ëª… ì—†ìŒ"
    prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì´ë©”ì¼ì„ ì¶”ì¶œí•´ì¤˜. ì—†ìœ¼ë©´ ì˜¤ì§ 'None'ì´ë¼ê³ ë§Œ ë‹µí•´: {desc}"
    try:
        time.sleep(1) # AIì—ê²Œ ìƒê°í•  ì‹œê°„(1ì´ˆ)ì„ ì£¼ì–´ ê³¼ë¶€í•˜ ë°©ì§€
        response = model.generate_content(prompt)
        res = response.text.strip()
        if "@" in res and len(res) < 50: return res
        return "AI ë¶„ì„ ì–´ë ¤ì›€ (ì§ì ‘ í™•ì¸ í•„ìš”)"
    except Exception as e:
        if "429" in str(e): return "AI ì¼ì‹œ ì¤‘ë‹¨ (ì ì‹œ í›„ ì‹œë„)"
        return "ë°ì´í„° í™•ì¸ í•„ìš”"

def check_performance(up_id, subs):
    if not (min_subs <= subs <= max_subs): return False, 0, 0
    try:
        req = YOUTUBE.playlistItems().list(part="contentDetails", playlistId=up_id, maxResults=15).execute()
        v_ids = [i['contentDetails']['videoId'] for i in req.get('items', [])]
        v_res = YOUTUBE.videos().list(part="statistics,contentDetails", id=",".join(v_ids)).execute()
        longforms = [v for v in v_res['items'] if 'M' in v['contentDetails']['duration'] or 'H' in v['contentDetails']['duration']][:10]
        if not longforms: return False, 0, 0
        avg_v = sum(int(v['statistics'].get('viewCount', 0)) for v in longforms) / len(longforms)
        eff = avg_v / subs
        return (eff >= efficiency_target), avg_v, eff
    except Exception as e:
        if "quotaExceeded" in str(e): handle_api_error(e)
        return False, 0, 0

# [ìˆ˜ì •ë¨] ë”¥ë¦¬ì„œì¹˜ AI ê´‘ê³  íŒë³„ ì‹œ ê³¼ë¶€í•˜ ë°©ì§€ í“¨ì¦ˆ ì„¤ì¹˜
# --- [ìˆ˜ì •ëœ í•µì‹¬ í•¨ìˆ˜: ê³µì‹ í‘œê¸° ê°ì§€ + AI ì •ë°€ ë¶„ì„] ---
def get_recent_ad_videos_ai(up_id, count):
    try:
        # 1. ì˜ìƒ ë°ì´í„° ìˆ˜ì§‘
        req = YOUTUBE.playlistItems().list(part="snippet,contentDetails", playlistId=up_id, maxResults=count).execute()
        v_ids = [i['contentDetails']['videoId'] for i in req.get('items', [])]
        v_res = YOUTUBE.videos().list(part="snippet,statistics", id=",".join(v_ids)).execute()
        
        all_videos = []
        ad_found_indices = [] # ê³µì‹ í‘œê¸°ë¡œ ì°¾ì€ ê´‘ê³  ì¸ë±ìŠ¤ ì €ì¥

        # ê³µì‹ ê´‘ê³  í‘œê¸° íŒ¨í„´ (ìœ íŠœë¸Œ ê°€ì´ë“œë¼ì¸ ë° ê³µì •ìœ„ ê¸°ì¤€)
        official_patterns = [
            "ìœ ë£Œ ê´‘ê³  í¬í•¨", "Paid promotion", "ì œì‘ ì§€ì›", "ìœ ë£Œ í˜‘ì°¬", 
            "#ê´‘ê³ ", "#í˜‘ì°¬", "Product provided", "Sponsored"
        ]

        for idx, v in enumerate(v_res.get('items', [])):
            title = v['snippet']['title']
            desc = v['snippet'].get('description', '')
            
            video_data = {
                "ì˜ìƒ ì œëª©": title,
                "ì„¤ëª…": desc[:1000],
                "ì—…ë¡œë“œ ì¼ì": datetime.strptime(v['snippet']['publishedAt'], '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d'),
                "ì¡°íšŒìˆ˜": int(v['statistics'].get('viewCount', 0)),
                "ì˜ìƒ ë§í¬": f"https://youtu.be/{v['id']}",
                "íŒë‹¨ê·¼ê±°": ""
            }

            # 1ë‹¨ê³„: í”„ë¡œê·¸ë¨ì´ 'ê³µì‹ ë¬¸êµ¬'ë¥¼ ì§ì ‘ ê²€ì‚¬ (ë§¤ìš° ë¹ ë¦„)
            for pattern in official_patterns:
                if pattern in title or pattern in desc[:200]: # ì œëª©ì´ë‚˜ ì„¤ëª…ë€ ì•ë¶€ë¶„ ì§‘ì¤‘ ê²€ì‚¬
                    video_data["íŒë‹¨ê·¼ê±°"] = f"ê³µì‹ í‘œê¸° ê°ì§€({pattern})"
                    ad_found_indices.append(idx)
                    break
            
            all_videos.append(video_data)
        
        if not all_videos: return pd.DataFrame()

        # 2ë‹¨ê³„: ê³µì‹ í‘œê¸°ê°€ ì—†ëŠ” ì˜ìƒë“¤ë§Œ ëª¨ì•„ì„œ AIì—ê²Œ 2ì°¨ íŒë³„ ìš”ì²­ (AX ê°•í™”)
        remaining_indices = [i for i in range(len(all_videos)) if i not in ad_found_indices]
        
        if remaining_indices:
            video_text = "\n".join([f"[{i}] ì œëª©: {all_videos[i]['ì˜ìƒ ì œëª©']} / ì„¤ëª…: {all_videos[i]['ì„¤ëª…'][:150]}" for i in remaining_indices])
            prompt = f"""
            ë‹¤ìŒ ìœ íŠœë¸Œ ì˜ìƒ ë¦¬ìŠ¤íŠ¸ì—ì„œ 'ê³µì‹ í‘œê¸°ëŠ” ì—†ì§€ë§Œ' ê´‘ê³ ë‚˜ í˜‘ì°¬ì´ í™•ì‹¤í•´ ë³´ì´ëŠ” ì˜ìƒì„ ê³¨ë¼ì¤˜.
            (ì˜ˆ: í• ì¸ì½”ë“œ ì œê³µ, íŠ¹ì • ë¸Œëœë“œ ì‡¼í•‘ëª° ë§í¬, ì œí’ˆ ì œê³µ ì–¸ê¸‰ ë“±)
            ê´‘ê³ ê°€ ì—†ë‹¤ë©´ 'None'ì´ë¼ê³  ë‹µí•´. í˜•ì‹: 0, 2, 5
            
            ë¦¬ìŠ¤íŠ¸:
            {video_text}
            """
            
            try:
                time.sleep(1) # í• ë‹¹ëŸ‰ ë³´í˜¸
                response = model.generate_content(prompt)
                ai_res = response.text.strip()
                if "None" not in ai_res:
                    ai_indices = [int(i.strip()) for i in ai_res.split(",") if i.strip().isdigit()]
                    for i in ai_indices:
                        if i < len(all_videos):
                            all_videos[i]["íŒë‹¨ê·¼ê±°"] = "AI ì •ë°€ ë¶„ì„ ê°ì§€"
                            ad_found_indices.append(i)
            except Exception as e:
                if "429" in str(e):
                    st.caption("âš ï¸ AI 2ì°¨ ë¶„ì„ì€ í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ ê±´ë„ˆëœë‹ˆë‹¤. (ê³µì‹ í‘œê¸° ìœ„ì£¼ë¡œ í‘œì‹œ)")
                pass

        # 3ë‹¨ê³„: ìµœì¢… ê´‘ê³  ì˜ìƒ ë¦¬ìŠ¤íŠ¸ êµ¬ì„± (ì¤‘ë³µ ì œê±° ë° ì •ë ¬)
        final_ad_indices = sorted(list(set(ad_found_indices)))
        ad_videos = [all_videos[i] for i in final_ad_indices]
        
        return pd.DataFrame(ad_videos)[["ì˜ìƒ ì œëª©", "ì—…ë¡œë“œ ì¼ì", "ì¡°íšŒìˆ˜", "íŒë‹¨ê·¼ê±°", "ì˜ìƒ ë§í¬"]]
    except: return pd.DataFrame()

# --- [6. ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤] ---
if "search_results" not in st.session_state:
    st.session_state.search_results = None

if submit_button:
    if not keywords_input:
        st.warning("âš ï¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        exclude_data = extract_exclude_list(exclude_file) if exclude_file else set()
        kws = [k.strip() for k in keywords_input.split(",")]
        final_list = []
        prog = st.progress(0)
        curr = 0
        total = len(kws) * max_res

        with st.status("ğŸ” ë°ì´í„° ìˆ˜ì§‘ ë° AI Transformation ë¶„ì„ ì¤‘...", expanded=True) as status:
            for kw in kws:
                search = YOUTUBE.search().list(q=kw, part="snippet", type="channel", maxResults=max_res, regionCode=COUNTRIES[selected_country]).execute()
                for item in search['items']:
                    curr += 1
                    prog.progress(min(curr/total, 1.0))
                    title = item['snippet']['title']
                    channel_id = item['snippet']['channelId']
                    channel_url = f"https://youtube.com/channel/{channel_id}"
                    
                    if title.strip() in exclude_data or channel_url in exclude_data or channel_id in exclude_data:
                        continue

                    try:
                        ch = YOUTUBE.channels().list(part="snippet,statistics,contentDetails", id=channel_id).execute()['items'][0]
                        subs = int(ch['statistics'].get('subscriberCount', 0))
                        up_id = ch['contentDetails']['relatedPlaylists']['uploads']
                        is_ok, avg_v, eff = check_performance(up_id, subs)
                        if is_ok:
                            final_list.append({
                                "ì±„ë„ëª…": title, "êµ¬ë…ì": subs, "í‰ê·  ì¡°íšŒìˆ˜": round(avg_v),
                                "íš¨ìœ¨": f"{eff*100:.1f}%", "ì´ë©”ì¼": extract_email_ai(ch['snippet']['description']),
                                "URL": channel_url, "í”„ë¡œí•„": ch['snippet']['thumbnails']['default']['url'],
                                "upload_id": up_id
                            })
                    except: continue
            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)
        st.session_state.search_results = pd.DataFrame(final_list)

# --- [7. ê²°ê³¼ ì¶œë ¥ ë° AI ê´‘ê³  ë”¥ë¦¬ì„œì¹˜] ---
if isinstance(st.session_state.search_results, pd.DataFrame) and not st.session_state.search_results.empty:
    st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    st.caption("ğŸ’¡ ì±„ë„ì„ í´ë¦­í•˜ë©´ í•˜ë‹¨ì— AIê°€ íŒë³„í•œ 'ìµœê·¼ ê´‘ê³ /í˜‘ì—… ì˜ìƒ' ë¦¬ìŠ¤íŠ¸ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
    
    event = st.dataframe(
        st.session_state.search_results,
        column_config={
            "í”„ë¡œí•„": st.column_config.ImageColumn("í”„ë¡œí•„", width="small"),
            "URL": st.column_config.LinkColumn("ì±„ë„ ë§í¬", display_text="ë°”ë¡œê°€ê¸°"),
            "êµ¬ë…ì": st.column_config.NumberColumn(format="%dëª…"),
            "í‰ê·  ì¡°íšŒìˆ˜": st.column_config.NumberColumn(format="%díšŒ"),
            "upload_id": None
        },
        use_container_width=True, hide_index=True, on_select="rerun", selection_mode="single-row"
    )

    if event.selection.rows:
        selected_idx = event.selection.rows[0]
        ch_info = st.session_state.search_results.iloc[selected_idx]
        st.markdown("---")
        st.subheader(f"ğŸ” '{ch_info['ì±„ë„ëª…']}' AI ê´‘ê³  ë¶„ì„")
        
        analysis_count = st.selectbox("ë¶„ì„ ë²”ìœ„ ì„¤ì • (ìµœê·¼ ì˜ìƒ)", [10, 20, 30], index=1)
        
        with st.spinner(f"AIë¡œ ìµœê·¼ ê´‘ê³  í˜‘ì—… ì‚¬ë¡€ë¥¼ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            ad_df = get_recent_ad_videos_ai(ch_info['upload_id'], analysis_count)
            
            if not ad_df.empty:
                st.success(f"ğŸ¯ ì´ {len(ad_df)}ê°œì˜ ìµœê·¼ ê´‘ê³ /í˜‘ì—… ì˜ìƒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.dataframe(
                    ad_df,
                    column_config={"ì˜ìƒ ë§í¬": st.column_config.LinkColumn("ì˜ìƒ ë³´ê¸°", display_text="ì´ë™"), "ì¡°íšŒìˆ˜": st.column_config.NumberColumn(format="%díšŒ")},
                    use_container_width=True, hide_index=True
                )
                csv = ad_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button(f"ğŸ“¥ {ch_info['ì±„ë„ëª…']} ê´‘ê³  ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ", data=csv, file_name=f"Ads_{ch_info['ì±„ë„ëª…']}.csv")
            else:
                st.warning("ğŸ§ ë¶„ì„ ë²”ìœ„ ë‚´ì—ì„œ ìµœê·¼ ê´‘ê³  í˜‘ì—… ì˜ìƒì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
