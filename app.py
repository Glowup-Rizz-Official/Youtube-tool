import streamlit as st
import pandas as pd
import re
import time
import os
import json
from datetime import datetime, timedelta
import googleapiclient.discovery
import google.generativeai as genai

# --- [0. íŒ€ ê³µìš© í• ë‹¹ëŸ‰ ê´€ë¦¬ ì‹œìŠ¤í…œ ë¡œì§] ---
QUOTA_FILE = "quota.json"

def load_global_stats():
    if not os.path.exists(QUOTA_FILE):
        return {"yt_total": 0, "ai_total": 0, "last_reset": datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
    with open(QUOTA_FILE, "r") as f:
        try: return json.load(f)
        except: return {"yt_total": 0, "ai_total": 0, "last_reset": datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

def save_global_stats(stats):
    with open(QUOTA_FILE, "w") as f:
        json.dump(stats, f)

def check_and_reset_quota():
    stats = load_global_stats()
    now = datetime.now()
    last_reset = datetime.strptime(stats["last_reset"], "%Y-%m-%d %H:%M:%S")
    reset_time_today = now.replace(hour=17, minute=0, second=0, microsecond=0)
    
    # 17:00 KST ìë™ ë¦¬ì…‹ ë¡œì§
    if now >= reset_time_today and last_reset < reset_time_today:
        stats["yt_total"] = 0
        stats["last_reset"] = now.strftime("%Y-%m-%d %H:%M:%S")
        save_global_stats(stats)
    return stats

def track_points_global(amount, is_ai=False):
    stats = load_global_stats()
    if is_ai: stats["ai_total"] += 1
    else: stats["yt_total"] += amount
    save_global_stats(stats)

# --- [1. ë³´ì•ˆ ë° API ì„¤ì •] ---
try:
    YOUTUBE_KEY = st.secrets["YOUTUBE_API_KEY"]
    GEMINI_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("ğŸš¨ ë³´ì•ˆ ì„¤ì •(.streamlit/secrets.toml)ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

genai.configure(api_key=GEMINI_KEY)
model = genai.GenerativeModel('models/gemini-2.0-flash')
YOUTUBE = googleapiclient.discovery.build('youtube', 'v3', developerKey=YOUTUBE_KEY)

# --- [2. ë°ì´í„° ì„¤ì •] ---
COUNTRIES = {"ëŒ€í•œë¯¼êµ­": "KR", "ë¯¸êµ­": "US", "ì¼ë³¸": "JP", "ì˜êµ­": "GB", "ë² íŠ¸ë‚¨": "VN", "íƒœêµ­": "TH", "ì¸ë„ë„¤ì‹œì•„": "ID", "ëŒ€ë§Œ": "TW"}
SUB_RANGES = {"ì „ì²´": (0, 100000000), "1ë§Œ ë¯¸ë§Œ": (0, 10000), "1ë§Œ ~ 5ë§Œ": (10000, 50000), "5ë§Œ ~ 10ë§Œ": (50000, 100000), "10ë§Œ ~ 50ë§Œ": (100000, 500000), "50ë§Œ ~ 100ë§Œ": (500000, 1000000), "100ë§Œ ì´ìƒ": (1000000, 100000000)}

# --- [3. UI ì„¤ì • ë° ì‚¬ì´ë“œë°” (ë¡œê³  + ëª¨ë‘ì—ê²Œ ë³´ì´ëŠ” í˜„í™© + ë¹„ë²ˆ ì˜ì—­)] ---
st.set_page_config(page_title="Glowup Rizz - íŒ€ ê³µìš© AX ì—”ì§„", layout="wide")
global_stats = check_and_reset_quota()

with st.sidebar:
    # 1. ë¡œê³  (ê¸°ì¡´ ìœ ì§€)
    try:
        st.image("logo.png", use_container_width=True)
    except:
        pass
    
    st.markdown("---")
    
    # 2. íŒ€ ê³µìš© ëŒ€ì‹œë³´ë“œ (ê¸°ì¡´ ìœ ì§€ - ëª¨ë“  ìœ ì €ì—ê²Œ ë…¸ì¶œ)
    st.subheader("ğŸ‘¥ íŒ€ ê³µìš© API í˜„í™©")
    yt_pts = global_stats["yt_total"]
    st.write(f"**YouTube API ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰**")
    st.progress(min(yt_pts / 500000, 1.0))
    st.caption(f"{yt_pts:,} / 500,000 pts (17:00 ë¦¬ì…‹)")
    
    st.write(f"**Gemini AI ëˆ„ì  í˜¸ì¶œ**")
    st.metric("Total AI Calls", f"{global_stats['ai_total']:,} íšŒ")
    st.caption("ê²°ì œ ê¸ˆì•¡ ì‚°ì •ì„ ìœ„í•´ ê³„ì† ëˆ„ì ë©ë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # 3. ê´€ë¦¬ì ì „ìš© ì˜ì—­ (ë¹„ë°€ë²ˆí˜¸ ê²€ì‚¬ ë¡œì§ë§Œ ë³´ì•ˆ ê°•í™”)
    st.subheader("ğŸ” ê´€ë¦¬ì ì „ìš©")
    
    # ê¸ˆê³ (Secrets)ì—ì„œ ì •ë‹µ ë¹„ë°€ë²ˆí˜¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. 
    correct_password = st.secrets.get("ADMIN_PASSWORD", "rizz1000")
    
    admin_pw = st.text_input("ë¦¬ì…‹ ë¹„ë°€ë²ˆí˜¸", type="password", placeholder="Password required to reset")
    
    #ì…ë ¥ê°’ ê¸ˆê³  ë¹„êµ
    if admin_pw == correct_password:
        st.success("âœ… ê´€ë¦¬ì ì¸ì¦ ì™„ë£Œ")
        if st.button("ğŸ”„ ëˆ„ì  ë°ì´í„° ì´ˆê¸°í™”"):
            global_stats["ai_total"] = 0
            save_global_stats(global_stats)
            st.toast("AI ë°ì´í„°ê°€ 0ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    elif admin_pw != "":
        st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ë©”ì¸ íƒ€ì´í‹€
st.title("ğŸŒ YOUTUBE í¬ë¦¬ì—ì´í„° ê²€ìƒ‰ ì—”ì§„")
st.markdown("ë¬¸ì˜ 010-8900-6756")
st.markdown("---")

# --- [4. í•˜ì´ë¸Œë¦¬ë“œ ë¡œì§ í•¨ìˆ˜ë“¤] ---
def extract_email_hybrid(desc):
    if not desc or len(desc.strip()) < 5: return "ì§ì ‘ í™•ì¸ í•„ìš”"
    reg = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', desc)
    if reg: return reg[0]
    try:
        time.sleep(0.5)
        track_points_global(1, is_ai=True) # AI ì‚¬ìš© ì‹œ ê³µìš© DB ì—…ë°ì´íŠ¸
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ë©”ì¼ì„ ì°¾ì•„ì¤˜. ì—†ìœ¼ë©´ 'None': {desc}"
        res = model.generate_content(prompt).text.strip()
        return res if "@" in res else "ì§ì ‘ í™•ì¸ í•„ìš”"
    except: return "ë°ì´í„° í™•ì¸ í•„ìš”"

def check_performance(up_id, subs, min_s, max_s, target_eff):
    if not (min_s <= subs <= max_s): return False, 0, 0
    try:
        req = YOUTUBE.playlistItems().list(part="contentDetails", playlistId=up_id, maxResults=15).execute()
        track_points_global(1)
        v_ids = [i['contentDetails']['videoId'] for i in req.get('items', [])]
        v_res = YOUTUBE.videos().list(part="statistics,contentDetails", id=",".join(v_ids)).execute()
        track_points_global(1)
        longforms = [v for v in v_res['items'] if 'M' in v['contentDetails']['duration'] or 'H' in v['contentDetails']['duration']][:10]
        if not longforms: return False, 0, 0
        avg_v = sum(int(v['statistics'].get('viewCount', 0)) for v in longforms) / len(longforms)
        eff = avg_v / subs
        return (eff >= target_eff), avg_v, eff
    except: return False, 0, 0

def get_year_ad_history(up_id):
    one_year_ago = (datetime.utcnow() - timedelta(days=365)).isoformat() + "Z"
    all_ads = []
    next_token = None
    patterns = ["ìœ ë£Œ ê´‘ê³  í¬í•¨", "Paid promotion", "í˜‘ì°¬", "#ê´‘ê³ ", "AD"]
    
    with st.spinner("1ë…„ ì¹˜ ë°ì´í„°ë¥¼ ì „ìˆ˜ ì¡°ì‚¬ ì¤‘..."):
        while True:
            req = YOUTUBE.playlistItems().list(part="snippet,contentDetails", playlistId=up_id, maxResults=50, pageToken=next_token).execute()
            track_points_global(1)
            v_ids = [item['contentDetails']['videoId'] for item in req.get('items', []) if item['snippet']['publishedAt'] >= one_year_ago]
            
            if v_ids:
                v_res = YOUTUBE.videos().list(part="snippet,statistics", id=",".join(v_ids)).execute()
                track_points_global(1)
                for v in v_res.get('items', []):
                    title, desc = v['snippet']['title'], v['snippet'].get('description', '')
                    if any(p in title or p in desc[:300] for p in patterns):
                        all_ads.append({
                            "ì˜ìƒ ì œëª©": title, "ì—…ë¡œë“œ ì¼ì": v['snippet']['publishedAt'][:10],
                            "ì¡°íšŒìˆ˜": int(v['statistics'].get('viewCount', 0)),
                            "ì˜ìƒ ë§í¬": f"https://youtu.be/{v['id']}"
                        })
            
            if len(v_ids) < len(req.get('items', [])): break # 1ë…„ ì§€ë‚œ ì˜ìƒ ë°œê²¬ ì‹œ ì¤‘ë‹¨
            next_token = req.get('nextPageToken')
            if not next_token: break
    return pd.DataFrame(all_ads)

# --- [5. ë©”ì¸ ê²€ìƒ‰ í¼ (í•„í„° ìœ ì§€)] ---
with st.form("search_form"):
    st.markdown("ğŸ“¥ **ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ ì œì™¸í•˜ê¸° (íŒŒì¼ ì—…ë¡œë“œ)**")
    exclude_file = st.file_uploader("ì´ë¯¸ í™•ë³´í•œ ì±„ë„ ë¦¬ìŠ¤íŠ¸ ì—…ë¡œë“œ", type=['xlsx', 'csv'])
    st.markdown("---")
    
    r1_c1, r1_c2, r1_c3 = st.columns([3, 1, 1])
    with r1_c1: keywords_input = st.text_input("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ë¨¹ë°©, ì¼ìƒ ë¸Œì´ë¡œê·¸")
    with r1_c2: selected_country = st.selectbox("ë¶„ì„ êµ­ê°€", list(COUNTRIES.keys()))
    with r1_c3: search_mode = st.radio("ë¶„ì„ ë°©ì‹", ["ì˜ìƒ ì½˜í…ì¸  ê¸°ë°˜", "ì±„ë„ëª… ê¸°ë°˜"], horizontal=True)

    r2_c1, r2_c2, r2_c3 = st.columns(3)
    with r2_c1:
        selected_sub_range = st.selectbox("ğŸ¯ êµ¬ë…ì ë²”ìœ„ ì„ íƒ", list(SUB_RANGES.keys()))
        min_s, max_s = SUB_RANGES[selected_sub_range]
    with r2_c2: efficiency_target = st.slider("ğŸ“ˆ ìµœì†Œ ì¡°íšŒìˆ˜ íš¨ìœ¨ (%)", 0, 100, 30) / 100
    with r2_c3: max_res = st.number_input("ğŸ” ë¶„ì„ ìƒ˜í”Œ ìˆ˜ (í‚¤ì›Œë“œë‹¹)", 5, 50, 20)
    
    submit_button = st.form_submit_button("ğŸš€ í†µí•© ê²€ìƒ‰ ì‹œì‘")

# --- [6. ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥ (ê¸°ì¡´ ë¡œì§ ë™ì¼)] ---
if submit_button:
    if not keywords_input:
        st.warning("âš ï¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        kws = [k.strip() for k in keywords_input.split(",")]
        final_list = []
        processed_channels = set()
        prog = st.progress(0)
        curr = 0
        total = len(kws) * max_res

        with st.status("ğŸ” ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ ì¤‘...", expanded=True) as status:
            for kw in kws:
                mode_type = "video" if "ì˜ìƒ" in search_mode else "channel"
                search = YOUTUBE.search().list(q=kw, part="snippet", type=mode_type, maxResults=max_res, regionCode=COUNTRIES[selected_country]).execute()
                track_points_global(100) # ê²€ìƒ‰ í¬ì¸íŠ¸ ëˆ„ì 
                
                for item in search['items']:
                    curr += 1
                    prog.progress(min(curr/total, 1.0))
                    ch_id = item['snippet']['channelId']
                    if ch_id in processed_channels: continue
                    processed_channels.add(ch_id)
                    
                    try:
                        ch = YOUTUBE.channels().list(part="snippet,statistics,contentDetails", id=ch_id).execute()['items'][0]
                        track_points_global(1)
                        subs = int(ch['statistics'].get('subscriberCount', 0))
                        is_ok, avg_v, eff = check_performance(ch['contentDetails']['relatedPlaylists']['uploads'], subs, min_s, max_s, efficiency_target)
                        if is_ok:
                            final_list.append({
                                "ì±„ë„ëª…": ch['snippet']['title'], "êµ¬ë…ì": subs, "í‰ê· ì¡°íšŒìˆ˜": round(avg_v),
                                "íš¨ìœ¨": f"{eff*100:.1f}%", "ì´ë©”ì¼": extract_email_hybrid(ch['snippet']['description']),
                                "URL": f"https://youtube.com/channel/{ch_id}",
                                "í”„ë¡œí•„": ch['snippet']['thumbnails']['default']['url'], "upload_id": ch['contentDetails']['relatedPlaylists']['uploads']
                            })
                    except: continue
            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete")
        st.session_state.search_results = pd.DataFrame(final_list)

if "search_results" in st.session_state and not st.session_state.search_results.empty:
    st.subheader("ğŸ“Š í†µí•© ë¶„ì„ ê²°ê³¼")
    event = st.dataframe(
        st.session_state.search_results,
        column_config={"í”„ë¡œí•„": st.column_config.ImageColumn("í”„ë¡œí•„"), "URL": st.column_config.LinkColumn("ë§í¬", display_text="ë°”ë¡œê°€ê¸°"), "upload_id": None},
        use_container_width=True, hide_index=True, on_select="rerun", selection_mode="single-row"
    )

    if event.selection.rows:
        selected_idx = event.selection.rows[0]
        ch_info = st.session_state.search_results.iloc[selected_idx]
        st.markdown("---")
        st.subheader(f"ğŸ“… '{ch_info['ì±„ë„ëª…']}' 1ë…„ ê´‘ê³  íˆìŠ¤í† ë¦¬ ì „ìˆ˜ ì¡°ì‚¬")
        ad_df = get_year_ad_history(ch_info['upload_id'])
        if not ad_df.empty:
            st.success(f"ğŸ¯ ì´ {len(ad_df)}ê°œì˜ ê´‘ê³ /í˜‘ì—… ì˜ìƒ ê°ì§€!")
            st.dataframe(ad_df, column_config={"ì˜ìƒ ë§í¬": st.column_config.LinkColumn("ë§í¬", display_text="ë°”ë¡œê°€ê¸°"), "ì¡°íšŒìˆ˜": st.column_config.NumberColumn(format="%díšŒ")}, use_container_width=True, hide_index=True)
        else:
            st.warning("ğŸ§ ìµœê·¼ 1ë…„ ì´ë‚´ì— ê°ì§€ëœ ê´‘ê³  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
